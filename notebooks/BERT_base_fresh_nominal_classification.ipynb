{"cells":[{"cell_type":"markdown","source":["V1 uses accuracy as performance metric"],"metadata":{"id":"2fcb1kklPHDX"},"id":"2fcb1kklPHDX"},{"cell_type":"markdown","metadata":{"id":"BVyRl3E3HAqQ"},"source":["# Imports"],"id":"BVyRl3E3HAqQ"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hMwUF8qUX_WJ","executionInfo":{"status":"ok","timestamp":1669838181878,"user_tz":480,"elapsed":346,"user":{"displayName":"Kurt Eulau","userId":"04832524453730868662"}},"outputId":"fd6f15ea-5655-40d1-dc1f-c335afddd856"},"outputs":[{"output_type":"stream","name":"stdout","text":["Wed Nov 30 19:56:21 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  A100-SXM4-40GB      Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   25C    P0    43W / 400W |      0MiB / 40536MiB |      0%      Default |\n","|                               |                      |             Disabled |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"],"id":"hMwUF8qUX_WJ"},{"cell_type":"code","execution_count":null,"metadata":{"id":"NuTilifJIY2a","executionInfo":{"status":"ok","timestamp":1669838197682,"user_tz":480,"elapsed":15807,"user":{"displayName":"Kurt Eulau","userId":"04832524453730868662"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c84ed920-1738-435d-ab7d-c0d2a66ce42d"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 5.5 MB 14.6 MB/s \n","\u001b[K     |████████████████████████████████| 7.6 MB 74.4 MB/s \n","\u001b[K     |████████████████████████████████| 182 kB 84.4 MB/s \n","\u001b[K     |████████████████████████████████| 1.3 MB 13.2 MB/s \n","\u001b[?25h"]}],"source":["!pip install transformers --quiet\n","!pip install sentencepiece --quiet"],"id":"NuTilifJIY2a"},{"cell_type":"code","execution_count":null,"metadata":{"id":"r-_I54teGqvg"},"outputs":[],"source":["import os\n","import sys\n","import time\n","import string\n","import sklearn\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import gc\n","\n","from google.colab import drive\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MultiLabelBinarizer\n","from sklearn.metrics import mean_squared_error\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","\n","from tensorflow.keras.layers import Embedding, Input, Dense, Lambda\n","from tensorflow.keras.models import Model, load_model\n","import tensorflow.keras.backend as K\n","from tensorflow.keras.callbacks import EarlyStopping, \\\n","  LearningRateScheduler, ModelCheckpoint\n","from tensorflow.keras.metrics import RootMeanSquaredError\n","from transformers import BertTokenizer, TFBertModel, AutoModel, AutoTokenizer\n","from transformers import BertConfig, BertTokenizer, TFBertModel\n","import transformers"],"id":"r-_I54teGqvg"},{"cell_type":"markdown","metadata":{"id":"KeHDr51VLXrd"},"source":["## Global Variables and Google Drive Connect"],"id":"KeHDr51VLXrd"},{"cell_type":"code","execution_count":null,"metadata":{"id":"msHGuIgzLT9K"},"outputs":[],"source":["TESTING = False # use to truncate training data in order to speed up development\n","\n","RANDOM_STATE = 42\n","SEQUENCE_LENGTH = 512\n","BATCH_SIZE = 1\n","USER = 'Kurt'\n","RUBRIC_COLS = ['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n","PATIENCE = 2\n","LEARNING_RATE = 0.0001\n","LEARNING_RATE_DECAY = 0.1\n","EPOCHS = 4 # change\n","# Uncomment these two lines if you want to be able to be able to repeat calculations exactly on the same hardware\n","# However, the model will run more slowly (approx 1/3 speed)\n","# tf.keras.utils.set_random_seed(RANDOM_STATE)\n","# tf.config.experimental.enable_op_determinism()"],"id":"msHGuIgzLT9K"},{"cell_type":"code","execution_count":null,"metadata":{"id":"JfgvLGBMHP54","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669838226038,"user_tz":480,"elapsed":23235,"user":{"displayName":"Kurt Eulau","userId":"04832524453730868662"}},"outputId":"3980047f-4148-408f-da9a-6ef9f708f8e1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# Mount drive where you will do your work.\n","drive.mount('/content/drive')\n","if USER == 'Alex': \n","  root_dir = \"/content/drive/MyDrive/w266/\"\n","  project_folder = \"Final_Project/\"\n","elif USER == 'Kurt':\n","  root_dir = \"/content/drive/My Drive/266/\"\n","  project_folder = \"Final Project/\"\n","elif USER == 'Tom':\n","  root_dir = \"/content/drive/My Drive/UC Berkeley/W266 Natural Language Processing/\"\n","  project_folder = \"Final Project/\"\n","else:\n","  raise Exception(\"User unrecognized, must connect to shared drive\")\n","\n","def create_and_set_working_directory(project_folder):\n","  # check if your project folder exists. if not, it will be created.\n","  if os.path.isdir(root_dir + project_folder) == False:\n","    os.mkdir(root_dir + project_folder)\n","    print(root_dir + project_folder + ' did not exist but was created.')\n","\n","  # change the OS to use your project folder as the working directory\n","  os.chdir(root_dir + project_folder)\n","\n","  # create a test file to make sure it shows up in the right place\n","  # to test if all is working, you can uncomment these two lines below--it should write a file to the shared drive\n","  # !touch 'new_file_in_working_directory.txt'\n","  # print('\\nYour working directory was changed to ' + root_dir + project_folder + \\\n","  #       \"\\n\\nAn empty text file was created there. You can also run !pwd to confirm the current working directory.\" )\n","\n","os.chdir(root_dir + project_folder)"],"id":"JfgvLGBMHP54"},{"cell_type":"markdown","metadata":{"id":"3oMbf9-mIEff"},"source":["# Load Data and Create Data Sets"],"id":"3oMbf9-mIEff"},{"cell_type":"code","execution_count":null,"metadata":{"id":"o52m4SLjGsy8"},"outputs":[],"source":["#Pull training data with all columns\n","X_train = pd.read_csv('data/processed/X_train.csv')\n","y_train = pd.read_csv('data/processed/y_train.csv')\n","\n","#pull validation data with all columns \n","X_val = pd.read_csv('data/processed/X_val.csv')\n","y_val = pd.read_csv('data/processed/y_val.csv')\n","\n","#pull test data with all columns\n","# X_test = pd.read_csv('data/processed/X_test.csv')\n","# y_test = pd.read_csv('data/processed/y_test.csv')\n","\n","#drop all non-text columns and concatenate train and val into one dataset\n","train_data_from_file = pd.merge(X_train, y_train, on='essay_index', how='outer')\n","validation_data_from_file = pd.merge(X_val, y_val, on='essay_index', how='outer')\n","train_data_from_file.rename(columns={'vocabulary_y':'vocabulary'}, inplace= True)\n","validation_data_from_file.rename(columns={'vocabulary_y':'vocabulary'}, inplace= True)\n"],"id":"o52m4SLjGsy8"},{"cell_type":"code","source":["train_data_from_file.columns"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1zNHvZLcsXrC","executionInfo":{"status":"ok","timestamp":1669697689390,"user_tz":480,"elapsed":5,"user":{"displayName":"Kurt Eulau","userId":"04832524453730868662"}},"outputId":"50e08be2-26b5-4f6d-f4a8-997cebe881a5"},"id":"1zNHvZLcsXrC","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['Unnamed: 0_x', 'essay_index', 'text_id_x', 'full_text', 'spacy_doc',\n","       'paragraph_count', 'punctuation_count', 'character_count',\n","       'contraction_count', 'SCONJ', 'NUM', 'ADV', 'PRON', 'DET', 'AUX', 'ADJ',\n","       'SYM', 'CCONJ', 'PART', 'INTJ', 'PROPN', 'X', 'NOUN', 'SPACE', 'VERB',\n","       'PUNCT', 'ADP', 'syllable_count', 'words', 'word_count', 'title_count',\n","       'mean_word_length', 'variance_word_length', 'vocabulary_x', 'stopwords',\n","       'stopword_count', 'sentence_count', 'mean_sentence_length',\n","       'variance_sentence_length', 'polarity', 'subjectivity', 'fk_score',\n","       'Unnamed: 0_y', 'text_id_y', 'cohesion', 'syntax', 'vocabulary',\n","       'phraseology', 'grammar', 'conventions'],\n","      dtype='object')"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["# Other useful helper functions\n","def scores_to_ints(x):\n","  return (x-1.0)*2  # note this actually returns a float but is converted to int with astype later\n","\n","def ints_to_scores(x):\n","  return (int(x)/2.0)+1.0\n","\n","ints_to_scores_vectorized = np.vectorize(ints_to_scores)\n","\n","def select_data(train_data, val_data, rubric_col):\n","    train_data = train_data[['full_text',rubric_col]]\n","    train_data[rubric_col] = train_data[rubric_col].apply(scores_to_ints).astype(int)\n","    val_data = val_data[['full_text',rubric_col]]\n","    val_data[rubric_col] = val_data[rubric_col].apply(scores_to_ints).astype(int)\n","    \n","    return train_data, val_data"],"metadata":{"id":"dWZyPA8KZxcW"},"id":"dWZyPA8KZxcW","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1669697689391,"user":{"displayName":"Kurt Eulau","userId":"04832524453730868662"},"user_tz":480},"id":"ue5mPKuYR93h","outputId":"6a25a459-c6d3-4963-ae1c-213a3e8e699f"},"outputs":[{"output_type":"stream","name":"stdout","text":["input_data size is: (2347, 50)\n","validation data size is: (782, 50)\n"]}],"source":["if TESTING:\n","  train_size = 250\n","  val_size = 3\n","\n","  print(\"=========================================\\nIN TESTING MODE\\n=========================================\")\n","\n","else:\n","  train_size = 2347\n","  val_size = 782\n","\n","train_data_from_file = train_data_from_file[:train_size]\n","validation_data_from_file = validation_data_from_file[:val_size]\n","\n","print(\"input_data size is: {}\".format(train_data_from_file.shape))\n","print(\"validation data size is: {}\".format(validation_data_from_file.shape))"],"id":"ue5mPKuYR93h"},{"cell_type":"markdown","metadata":{"id":"XEG3R9wYnhdx"},"source":["## Tokenize Data"],"id":"XEG3R9wYnhdx"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3322,"status":"ok","timestamp":1669697692711,"user":{"displayName":"Kurt Eulau","userId":"04832524453730868662"},"user_tz":480},"id":"Y3Ek9TfMtggK","outputId":"472f11a3-a897-4498-b164-bc597201854b"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]}],"source":["# bert_model = AutoModel.from_pretrained(\"microsoft/bert-v3-base\")\n","# bert_tokenizer = transformers.AutoTokenizer.from_pretrained(\"microsoft/bert-v3-base\")\n","\n","bert_model = transformers.TFAutoModel.from_pretrained('bert-base-cased') # changed from deberta_base_fresh\n","bert_tokenizer = transformers.AutoTokenizer.from_pretrained('bert-base-cased') # changed from deberta_base_fresh\n","\n","auto_tune = tf.data.experimental.AUTOTUNE"],"id":"Y3Ek9TfMtggK"},{"cell_type":"code","execution_count":null,"metadata":{"id":"HDyQlm2m_Tkz"},"outputs":[],"source":["def bert_encode(texts, tokenizer, attn_mask):\n","    input_ids = []\n","    attention_mask = []\n","    \n","    for text in texts.tolist():\n","        token = tokenizer(text, \n","                          add_special_tokens=True, \n","                          max_length=SEQUENCE_LENGTH, \n","                          return_attention_mask=True, \n","                          return_tensors=\"np\", \n","                          truncation=True, \n","                          padding='max_length')\n","        input_ids.append(token['input_ids'][0])\n","        attention_mask.append(token['attention_mask'][0])\n","    if attn_mask:\n","      return np.array(input_ids, dtype=\"int32\"), np.array(attention_mask, dtype=\"int32\")\n","    else:\n","      return np.array(input_ids, dtype=\"int32\")\n","\n","\n","def get_data(df, rubric_col, attn_mask=True): # changed\n","    inputs = bert_encode(df['full_text'], bert_tokenizer, attn_mask)  \n","    targets = np.array(df[rubric_col], dtype=\"float32\") # changed\n","    return inputs, targets"],"id":"HDyQlm2m_Tkz"},{"cell_type":"markdown","metadata":{"id":"PzmIfem-wbC8"},"source":["# Loss and Metrics Functions"],"id":"PzmIfem-wbC8"},{"cell_type":"code","execution_count":null,"metadata":{"id":"frZQl1I6RBaA"},"outputs":[],"source":["# Using Huber loss which is less sensitive to outliers/edge cases\n","def huber_loss(y_true, y_pred, clip_delta=1.0):\n","  error = y_true - y_pred\n","  cond  = tf.keras.backend.abs(error) < clip_delta\n","\n","  squared_loss = 0.5 * tf.keras.backend.square(error)\n","  linear_loss  = clip_delta * (tf.keras.backend.abs(error) - 0.5 * clip_delta)\n","\n","  return tf.where(cond, squared_loss, linear_loss)\n","\n","keras.losses.huber_loss = huber_loss"],"id":"frZQl1I6RBaA"},{"cell_type":"code","execution_count":null,"metadata":{"id":"c83a5209"},"outputs":[],"source":["# Custom metric function MCRMSE : column wise root mean squared eoor\n","def MCRMSE(y_true, y_pred):\n","    colwise_mse = tf.reduce_mean(tf.square(y_true - y_pred), axis=0)\n","    return tf.reduce_mean(tf.sqrt(colwise_mse), axis=-1, keepdims=True)"],"id":"c83a5209"},{"cell_type":"markdown","metadata":{"id":"clB1IpglzX8X"},"source":["# Callbacks and LR "],"id":"clB1IpglzX8X"},{"cell_type":"code","execution_count":null,"metadata":{"id":"wU3I7VmVzM8V"},"outputs":[],"source":["#early stopping\n","earlystopper = tf.keras.callbacks.EarlyStopping(\n","      monitor='val_loss', patience = PATIENCE,\n","      restore_best_weights=True)"],"id":"wU3I7VmVzM8V"},{"cell_type":"code","execution_count":null,"metadata":{"id":"TCJcoA1izuEC"},"outputs":[],"source":["#learning rate schedule\n","def lr_scheduler(epoch, lr):\n","    \n","    if epoch < 7:\n","        return lr\n","    else:\n","        return lr * tf.math.exp(-0.1)\n","\n","lr_callback = tf.keras.callbacks.LearningRateScheduler(lr_scheduler)"],"id":"TCJcoA1izuEC"},{"cell_type":"markdown","metadata":{"id":"oUfQV7lPIgYj"},"source":["# Model Configurations"],"id":"oUfQV7lPIgYj"},{"cell_type":"code","execution_count":null,"metadata":{"id":"eRXZ8Q5lTUmJ"},"outputs":[],"source":["base_bert_config = dict(\n","    # RUBRIC_COLS = ['cohesion', 'syntax', 'vocabulary', \n","    #                'phraseology', 'grammar', 'conventions'], # changed\n","    batch_size = BATCH_SIZE,\n","    model_name = 'base_bert',\n","    epochs = EPOCHS,\n","    init_learning_rate = LEARNING_RATE,\n","    lr_decay_rate = LEARNING_RATE_DECAY,\n","    optimizer = 'adam',\n","    loss_fn = huber_loss,\n","    metrics = 'accuracy', # changed\n","    earlystopping_patience = PATIENCE\n",")"],"id":"eRXZ8Q5lTUmJ"},{"cell_type":"code","execution_count":null,"metadata":{"id":"WmkSju3sXKzh"},"outputs":[],"source":["cfg = transformers.AutoConfig.from_pretrained(\"bert-base-cased\", output_hidden_states=True) # Changed from deberta_base_fresh\n","cfg.hidden_dropout_prob = 0.3 # changed\n","cfg.attention_probs_dropout_prob = 0.3 # changed\n","# cfg.save_pretrained('./tokenizer/')"],"id":"WmkSju3sXKzh"},{"cell_type":"markdown","metadata":{"id":"aVxh7fuETpA_"},"source":["## bert Experiments"],"id":"aVxh7fuETpA_"},{"cell_type":"markdown","metadata":{"id":"yMUr92xZT_qU"},"source":["#### bert with pooled output"],"id":"yMUr92xZT_qU"},{"cell_type":"code","execution_count":null,"metadata":{"id":"qYPKHPCTTsV9"},"outputs":[],"source":["def create_bert_model(bert_model,\n","                      dropout = 0.3):\n","\n","    # Read in bert model's outputs\n","    input_ids = tf.keras.layers.Input(shape=(SEQUENCE_LENGTH,), dtype=tf.int64, name='input_ids_layer')\n","    attention_masks = tf.keras.layers.Input(shape=(SEQUENCE_LENGTH,), dtype=tf.int64, name='attention_mask_layer')\n","\n","    bert_output = bert_model.bert(\n","        input_ids, attention_mask=attention_masks\n","    )\n","    hidden_states = bert_output.last_hidden_state\n","\n","    x = tf.keras.layers.GlobalAveragePooling1D()(hidden_states)\n","    x = tf.keras.layers.LayerNormalization()(x)\n","    x = tf.keras.layers.Dropout(dropout)(x) \n","\n","    # # Prediction layer - predict cohesion via nomial classification\n","    output = tf.keras.layers.Dense(9, activation='softmax', name='classification_layer')(x) # changed\n","\n","    # # Make and compile model\n","    model = tf.keras.models.Model(inputs=(input_ids, attention_masks), outputs=[output]) \n","    model.compile(optimizer=tf.keras.optimizers.Adam(1e-5),  # changed\n","                    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False), # changed\n","                    metrics='accuracy') # changed\n","       \n","    return model"],"id":"qYPKHPCTTsV9"},{"cell_type":"markdown","metadata":{"id":"2PpYNQzeIrcv"},"source":["# Building Models"],"id":"2PpYNQzeIrcv"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6740,"status":"ok","timestamp":1669697726055,"user":{"displayName":"Kurt Eulau","userId":"04832524453730868662"},"user_tz":480},"id":"_zIGGLyJV1_8","outputId":"25e1eaa0-ef97-452a-b423-42fb4919a7bc"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"execute_result","data":{"text/plain":["23078"]},"metadata":{},"execution_count":33}],"source":["tf.keras.backend.clear_session()\n","\n","bert_model = transformers.TFAutoModel.from_pretrained(\"bert-base-cased\", config=cfg)\n","bert_pooled_model = create_bert_model(bert_model,\n","                                      dropout = 0.3)\n","\n","tf.keras.backend.clear_session()\n","\n","gc.collect()"],"id":"_zIGGLyJV1_8"},{"cell_type":"markdown","metadata":{"id":"J3MWhdMP2Hzg"},"source":["# Training Models"],"id":"J3MWhdMP2Hzg"},{"cell_type":"code","execution_count":null,"metadata":{"id":"VgEFYaMN2PVs"},"outputs":[],"source":["def train_model(model,\n","                train_df,\n","                val_df,\n","                config: dict,\n","                callbacks: list,\n","                verbose: int=0):\n","  \n","    # Initalize model\n","    tf.keras.backend.clear_session()\n","    callback = tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience = PATIENCE , restore_best_weights=True) # changed\n","\n","    model_history = model.fit(\n","      x=train_df[0],\n","      y=train_df[1],\n","      validation_data = val_df,\n","      batch_size=BATCH_SIZE,\n","      epochs=EPOCHS, # changed from EPOCHS\n","      shuffle = True, \n","      callbacks = [callback]\n","      )\n","\n","    return model_history"],"id":"VgEFYaMN2PVs"},{"cell_type":"code","source":["%%time\n","\n","pd.options.mode.chained_assignment = None\n","\n","RMSEs = list()\n","\n","for rubric_col in RUBRIC_COLS:\n","    print('\\n\\n////////////////////////////////////////////////////////////////////////////////////')\n","    print(f'\\nNow training on {rubric_col}...\\n')\n","    train_data, val_data = select_data(train_data_from_file, validation_data_from_file, rubric_col)\n","    train_dataset = get_data(train_data, rubric_col)\n","    val_dataset = get_data(val_data, rubric_col)\n","\n","    callbacks = [earlystopper]\n","\n","    tf.keras.backend.clear_session()\n","\n","    db_last_hidden_model = train_model(model=bert_pooled_model,\n","                            train_df = train_dataset, \n","                            val_df = val_dataset, \n","                            config=base_bert_config, \n","                            callbacks=callbacks, \n","                            verbose=1)\n","\n","    tf.keras.backend.clear_session()\n","\n","    preds_proba = bert_pooled_model.predict(val_dataset[0])\n","    preds_0_9 = tf.argmax(preds_proba, axis=-1)\n","    ints_to_scores_vectorized = np.vectorize(ints_to_scores)\n","    preds_1_5 = ints_to_scores_vectorized(np.array(preds_0_9).astype(int))\n","    val_labels = ints_to_scores_vectorized(val_dataset[1].astype(int))\n","    RMSEs.append(sklearn.metrics.mean_squared_error(val_labels, preds_1_5, squared=False))\n","    \n","\n","mcrmse_final = np.array(RMSEs).mean()\n","mcrmse_final"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O4MeIUdYpFi0","executionInfo":{"status":"ok","timestamp":1669699831859,"user_tz":480,"elapsed":2097112,"user":{"displayName":"Kurt Eulau","userId":"04832524453730868662"}},"outputId":"9d4e5151-0648-4d6a-f69c-fa31716d2c7e"},"id":"O4MeIUdYpFi0","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","////////////////////////////////////////////////////////////////////////////////////\n","\n","Now training on cohesion...\n","\n","Epoch 1/4\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"]},{"output_type":"stream","name":"stdout","text":["2347/2347 [==============================] - 91s 34ms/step - loss: 2.0705 - accuracy: 0.2650 - val_loss: 1.5475 - val_accuracy: 0.3133\n","Epoch 2/4\n","2347/2347 [==============================] - 78s 33ms/step - loss: 1.8433 - accuracy: 0.2825 - val_loss: 1.6180 - val_accuracy: 0.3146\n","Epoch 3/4\n","2347/2347 [==============================] - 77s 33ms/step - loss: 1.6926 - accuracy: 0.3349 - val_loss: 1.5648 - val_accuracy: 0.3286\n","Epoch 4/4\n","2347/2347 [==============================] - 79s 34ms/step - loss: 1.5970 - accuracy: 0.3485 - val_loss: 1.5080 - val_accuracy: 0.3440\n","25/25 [==============================] - 7s 147ms/step\n","\n","\n","////////////////////////////////////////////////////////////////////////////////////\n","\n","Now training on syntax...\n","\n","Epoch 1/4\n","2347/2347 [==============================] - 86s 36ms/step - loss: 1.5668 - accuracy: 0.3507 - val_loss: 1.7673 - val_accuracy: 0.2558\n","Epoch 2/4\n","2347/2347 [==============================] - 84s 36ms/step - loss: 1.4868 - accuracy: 0.3813 - val_loss: 1.5968 - val_accuracy: 0.3043\n","Epoch 3/4\n","2347/2347 [==============================] - 85s 36ms/step - loss: 1.3639 - accuracy: 0.4078 - val_loss: 2.0692 - val_accuracy: 0.2238\n","Epoch 4/4\n","2347/2347 [==============================] - 84s 36ms/step - loss: 1.2386 - accuracy: 0.4666 - val_loss: 1.6637 - val_accuracy: 0.3235\n","25/25 [==============================] - 5s 149ms/step\n","\n","\n","////////////////////////////////////////////////////////////////////////////////////\n","\n","Now training on vocabulary...\n","\n","Epoch 1/4\n","2347/2347 [==============================] - 89s 37ms/step - loss: 1.3791 - accuracy: 0.4239 - val_loss: 1.3849 - val_accuracy: 0.4003\n","Epoch 2/4\n","2347/2347 [==============================] - 85s 36ms/step - loss: 1.2549 - accuracy: 0.4589 - val_loss: 1.4497 - val_accuracy: 0.4207\n","Epoch 3/4\n","2347/2347 [==============================] - 85s 36ms/step - loss: 1.1621 - accuracy: 0.4998 - val_loss: 1.3832 - val_accuracy: 0.4322\n","Epoch 4/4\n","2347/2347 [==============================] - 85s 36ms/step - loss: 1.0336 - accuracy: 0.5424 - val_loss: 1.5375 - val_accuracy: 0.4054\n","25/25 [==============================] - 5s 148ms/step\n","\n","\n","////////////////////////////////////////////////////////////////////////////////////\n","\n","Now training on phraseology...\n","\n","Epoch 1/4\n","2347/2347 [==============================] - 89s 37ms/step - loss: 1.3823 - accuracy: 0.3911 - val_loss: 1.7361 - val_accuracy: 0.3069\n","Epoch 2/4\n","2347/2347 [==============================] - 85s 36ms/step - loss: 1.2480 - accuracy: 0.4461 - val_loss: 1.6875 - val_accuracy: 0.3338\n","Epoch 3/4\n","2347/2347 [==============================] - 85s 36ms/step - loss: 1.1657 - accuracy: 0.4802 - val_loss: 1.9294 - val_accuracy: 0.3146\n","Epoch 4/4\n","2347/2347 [==============================] - 85s 36ms/step - loss: 1.0156 - accuracy: 0.5513 - val_loss: 2.0239 - val_accuracy: 0.3095\n","25/25 [==============================] - 5s 150ms/step\n","\n","\n","////////////////////////////////////////////////////////////////////////////////////\n","\n","Now training on grammar...\n","\n","Epoch 1/4\n","2347/2347 [==============================] - 87s 36ms/step - loss: 1.4181 - accuracy: 0.3788 - val_loss: 1.4989 - val_accuracy: 0.3542\n","Epoch 2/4\n","2347/2347 [==============================] - 85s 36ms/step - loss: 1.2728 - accuracy: 0.4201 - val_loss: 1.7416 - val_accuracy: 0.3235\n","Epoch 3/4\n","2347/2347 [==============================] - 85s 36ms/step - loss: 1.1734 - accuracy: 0.4695 - val_loss: 1.9651 - val_accuracy: 0.3018\n","Epoch 4/4\n","2347/2347 [==============================] - 85s 36ms/step - loss: 1.0636 - accuracy: 0.5292 - val_loss: 2.0327 - val_accuracy: 0.3133\n","25/25 [==============================] - 5s 150ms/step\n","\n","\n","////////////////////////////////////////////////////////////////////////////////////\n","\n","Now training on conventions...\n","\n","Epoch 1/4\n","2347/2347 [==============================] - 89s 37ms/step - loss: 1.3655 - accuracy: 0.3835 - val_loss: 1.7085 - val_accuracy: 0.3184\n","Epoch 2/4\n","2347/2347 [==============================] - 85s 36ms/step - loss: 1.2277 - accuracy: 0.4423 - val_loss: 2.2685 - val_accuracy: 0.2634\n","Epoch 3/4\n","2347/2347 [==============================] - 85s 36ms/step - loss: 1.1222 - accuracy: 0.4934 - val_loss: 1.8459 - val_accuracy: 0.3491\n","Epoch 4/4\n","2347/2347 [==============================] - 85s 36ms/step - loss: 1.0007 - accuracy: 0.5577 - val_loss: 2.1408 - val_accuracy: 0.3389\n","25/25 [==============================] - 5s 149ms/step\n","CPU times: user 38min 22s, sys: 1min 25s, total: 39min 47s\n","Wall time: 34min 56s\n"]},{"output_type":"execute_result","data":{"text/plain":["0.5975440133352798"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["RMSEs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aBCCocBk3g3L","executionInfo":{"status":"ok","timestamp":1669699875351,"user_tz":480,"elapsed":201,"user":{"displayName":"Kurt Eulau","userId":"04832524453730868662"}},"outputId":"14b51b57-d103-4aee-c3d8-2f778089f117"},"id":"aBCCocBk3g3L","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.5707602503916246,\n"," 0.6113274307778798,\n"," 0.5182105744661055,\n"," 0.6449191547105203,\n"," 0.6214412750308917,\n"," 0.618605394634657]"]},"metadata":{},"execution_count":35}]},{"cell_type":"markdown","metadata":{"id":"03db3ebf"},"source":["# Prediction + Submission"],"id":"03db3ebf"},{"cell_type":"code","source":["# preds_proba = bert_pooled_model.predict(val_dataset[0])\n","# preds_proba"],"metadata":{"id":"viHVNqpCd7Di"},"id":"viHVNqpCd7Di","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# preds_0_9 = tf.argmax(preds_proba, axis=-1)\n","# preds_0_9[:20]"],"metadata":{"id":"W7zd5Fteebyu"},"id":"W7zd5Fteebyu","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ints_to_scores_vectorized = np.vectorize(ints_to_scores)"],"metadata":{"id":"Wv83HAqigL3d"},"id":"Wv83HAqigL3d","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# preds_1_5 = ints_to_scores_vectorized(np.array(preds_0_9).astype(int))\n","# preds_1_5[:20]"],"metadata":{"id":"LIu709WwgOpp"},"id":"LIu709WwgOpp","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# val_labels = ints_to_scores_vectorized(val_dataset[1].astype(int))\n","# val_labels[:20]"],"metadata":{"id":"8DHKy7vahxvM"},"id":"8DHKy7vahxvM","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# sklearn.metrics.mean_squared_error(val_labels, preds_1_5, squared=False)"],"metadata":{"id":"kR1wvKbWgxsz"},"id":"kR1wvKbWgxsz","execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[{"file_id":"1xHHoo3ndxfRT5n6SqLpl43Lovoo0H4ID","timestamp":1668995260169},{"file_id":"1PYoyeccegOeOXoMlLQGOsC34jST0wxmH","timestamp":1668984091622},{"file_id":"1VncoYfoa7Suog-5zq_VJlmwAsnJHY3gP","timestamp":1668960919745},{"file_id":"1c85_cBGeHnEX9OkmLcZXcljDPEGyDvg3","timestamp":1668893041333},{"file_id":"1IJuRuDVqZTCTu_lrzdd2Ga4X7xFlY3xX","timestamp":1664644852234}]},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"papermill":{"default_parameters":{},"duration":987.955368,"end_time":"2022-09-21T23:17:00.351231","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2022-09-21T23:00:32.395863","version":"2.3.4"}},"nbformat":4,"nbformat_minor":5}