{"cells":[{"cell_type":"markdown","source":["V1 uses accuracy as performance metric"],"metadata":{"id":"2fcb1kklPHDX"},"id":"2fcb1kklPHDX"},{"cell_type":"markdown","metadata":{"id":"BVyRl3E3HAqQ"},"source":["# Imports"],"id":"BVyRl3E3HAqQ"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hMwUF8qUX_WJ","executionInfo":{"status":"ok","timestamp":1669839457930,"user_tz":480,"elapsed":386,"user":{"displayName":"Kurt Eulau","userId":"04832524453730868662"}},"outputId":"cb2bf277-e7d8-42c2-ee25-1be8b00b02dc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Wed Nov 30 20:17:37 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  A100-SXM4-40GB      Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   30C    P0    61W / 400W |      0MiB / 40536MiB |      0%      Default |\n","|                               |                      |             Disabled |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"],"id":"hMwUF8qUX_WJ"},{"cell_type":"code","execution_count":null,"metadata":{"id":"NuTilifJIY2a"},"outputs":[],"source":["!pip install transformers --quiet\n","!pip install sentencepiece --quiet"],"id":"NuTilifJIY2a"},{"cell_type":"code","execution_count":null,"metadata":{"id":"r-_I54teGqvg"},"outputs":[],"source":["import os\n","import sys\n","import time\n","import string\n","import sklearn\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import gc\n","\n","from google.colab import drive\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MultiLabelBinarizer\n","from sklearn.metrics import mean_squared_error\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","\n","from tensorflow.keras.layers import Embedding, Input, Dense, Lambda\n","from tensorflow.keras.models import Model, load_model\n","import tensorflow.keras.backend as K\n","from tensorflow.keras.callbacks import EarlyStopping, \\\n","  LearningRateScheduler, ModelCheckpoint\n","from tensorflow.keras.metrics import RootMeanSquaredError\n","from transformers import BertTokenizer, TFBertModel, AutoModel, AutoTokenizer\n","from transformers import BertConfig, BertTokenizer, TFBertModel\n","import transformers"],"id":"r-_I54teGqvg"},{"cell_type":"markdown","metadata":{"id":"KeHDr51VLXrd"},"source":["## Global Variables and Google Drive Connect"],"id":"KeHDr51VLXrd"},{"cell_type":"code","execution_count":null,"metadata":{"id":"msHGuIgzLT9K"},"outputs":[],"source":["TESTING = False # use to truncate training data in order to speed up development\n","\n","RANDOM_STATE = 42\n","SEQUENCE_LENGTH = 512\n","BATCH_SIZE = 1\n","USER = 'Kurt'\n","RUBRIC_COLS = ['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n","PATIENCE = 2\n","LEARNING_RATE = 0.0001\n","LEARNING_RATE_DECAY = 0.1\n","EPOCHS = 4\n","# Uncomment these two lines if you want to be able to be able to repeat calculations exactly on the same hardware\n","# However, the model will run more slowly (approx 1/3 speed)\n","# tf.keras.utils.set_random_seed(RANDOM_STATE)\n","# tf.config.experimental.enable_op_determinism()"],"id":"msHGuIgzLT9K"},{"cell_type":"code","execution_count":null,"metadata":{"id":"JfgvLGBMHP54","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669839469197,"user_tz":480,"elapsed":923,"user":{"displayName":"Kurt Eulau","userId":"04832524453730868662"}},"outputId":"46d774fd-f8d4-41b0-8f9b-5baa9ce6c6fa"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["# Mount drive where you will do your work.\n","drive.mount('/content/drive')\n","if USER == 'Alex': \n","  root_dir = \"/content/drive/MyDrive/w266/\"\n","  project_folder = \"Final_Project/\"\n","elif USER == 'Kurt':\n","  root_dir = \"/content/drive/My Drive/266/\"\n","  project_folder = \"Final Project/\"\n","elif USER == 'Tom':\n","  root_dir = \"/content/drive/My Drive/UC Berkeley/W266 Natural Language Processing/\"\n","  project_folder = \"Final Project/\"\n","else:\n","  raise Exception(\"User unrecognized, must connect to shared drive\")\n","\n","def create_and_set_working_directory(project_folder):\n","  # check if your project folder exists. if not, it will be created.\n","  if os.path.isdir(root_dir + project_folder) == False:\n","    os.mkdir(root_dir + project_folder)\n","    print(root_dir + project_folder + ' did not exist but was created.')\n","\n","  # change the OS to use your project folder as the working directory\n","  os.chdir(root_dir + project_folder)\n","\n","  # create a test file to make sure it shows up in the right place\n","  # to test if all is working, you can uncomment these two lines below--it should write a file to the shared drive\n","  # !touch 'new_file_in_working_directory.txt'\n","  # print('\\nYour working directory was changed to ' + root_dir + project_folder + \\\n","  #       \"\\n\\nAn empty text file was created there. You can also run !pwd to confirm the current working directory.\" )\n","\n","os.chdir(root_dir + project_folder)"],"id":"JfgvLGBMHP54"},{"cell_type":"markdown","metadata":{"id":"3oMbf9-mIEff"},"source":["# Load Data and Create Data Sets"],"id":"3oMbf9-mIEff"},{"cell_type":"code","execution_count":null,"metadata":{"id":"o52m4SLjGsy8"},"outputs":[],"source":["#Pull training data with all columns\n","X_train = pd.read_csv('data/processed/X_train.csv')\n","y_train = pd.read_csv('data/processed/y_train.csv')\n","\n","#pull validation data with all columns \n","X_val = pd.read_csv('data/processed/X_val.csv')\n","y_val = pd.read_csv('data/processed/y_val.csv')\n","\n","#pull test data with all columns\n","X_test = pd.read_csv('data/processed/X_test.csv')\n","y_test = pd.read_csv('data/processed/y_test.csv')\n","\n","#drop all non-text columns and concatenate train and val into one dataset\n","train_data_from_file = pd.merge(X_train, y_train, on='essay_index', how='outer')\n","validation_data_from_file = pd.merge(X_val, y_val, on='essay_index', how='outer')\n","test_data_from_file = pd.merge(X_test, y_test, on='essay_index', how='outer')\n","\n","train_data_from_file.rename(columns={'vocabulary_y':'vocabulary'}, inplace= True)\n","validation_data_from_file.rename(columns={'vocabulary_y':'vocabulary'}, inplace= True)\n","test_data_from_file.rename(columns={'vocabulary_y':'vocabulary'}, inplace= True)\n"],"id":"o52m4SLjGsy8"},{"cell_type":"code","source":["# Other useful helper functions\n","def scores_to_ints(x):\n","  return (x-1.0)*2  # note this actually returns a float but is converted to int with astype later\n","\n","def ints_to_scores(x):\n","  return (int(x)/2.0)+1.0\n","\n","ints_to_scores_vectorized = np.vectorize(ints_to_scores)\n","\n","def select_data(train_data, val_data, test_data, rubric_col):\n","    train_data = train_data[['full_text',rubric_col]]\n","    train_data[rubric_col] = train_data[rubric_col].apply(scores_to_ints).astype(int)\n","    val_data = val_data[['full_text',rubric_col]]\n","    val_data[rubric_col] = val_data[rubric_col].apply(scores_to_ints).astype(int)\n","    test_data = test_data[['full_text',rubric_col]]\n","    test_data[rubric_col] = test_data[rubric_col].apply(scores_to_ints).astype(int)\n","    \n","    return train_data, val_data, test_data"],"metadata":{"id":"dWZyPA8KZxcW"},"id":"dWZyPA8KZxcW","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1669839469904,"user":{"displayName":"Kurt Eulau","userId":"04832524453730868662"},"user_tz":480},"id":"ue5mPKuYR93h","outputId":"cdefea42-6399-43ee-bcfe-47c5aa084d1e"},"outputs":[{"output_type":"stream","name":"stdout","text":["input_data size is: (2347, 50)\n","validation data size is: (782, 50)\n"]}],"source":["if TESTING:\n","  train_size = 250\n","  val_size = 3\n","\n","  print(\"=========================================\\nIN TESTING MODE\\n=========================================\")\n","\n","else:\n","  train_size = 2347\n","  val_size = 782\n","\n","train_data_from_file = train_data_from_file[:train_size]\n","validation_data_from_file = validation_data_from_file[:val_size]\n","\n","print(\"input_data size is: {}\".format(train_data_from_file.shape))\n","print(\"validation data size is: {}\".format(validation_data_from_file.shape))"],"id":"ue5mPKuYR93h"},{"cell_type":"markdown","metadata":{"id":"XEG3R9wYnhdx"},"source":["## Tokenize Data"],"id":"XEG3R9wYnhdx"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3190,"status":"ok","timestamp":1669839473092,"user":{"displayName":"Kurt Eulau","userId":"04832524453730868662"},"user_tz":480},"id":"Y3Ek9TfMtggK","outputId":"4c5a6057-b110-49c3-ecee-56eb3224ec4c"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]}],"source":["# bert_model = AutoModel.from_pretrained(\"microsoft/bert-v3-base\")\n","# bert_tokenizer = transformers.AutoTokenizer.from_pretrained(\"microsoft/bert-v3-base\")\n","\n","bert_model = transformers.TFAutoModel.from_pretrained('bert-base-cased') # changed from deberta_base_fresh\n","bert_tokenizer = transformers.AutoTokenizer.from_pretrained('bert-base-cased') # changed from deberta_base_fresh\n","\n","auto_tune = tf.data.experimental.AUTOTUNE"],"id":"Y3Ek9TfMtggK"},{"cell_type":"code","execution_count":null,"metadata":{"id":"HDyQlm2m_Tkz"},"outputs":[],"source":["def bert_encode(texts, tokenizer, attn_mask):\n","    input_ids = []\n","    attention_mask = []\n","    \n","    for text in texts.tolist():\n","        token = tokenizer(text, \n","                          add_special_tokens=True, \n","                          max_length=SEQUENCE_LENGTH, \n","                          return_attention_mask=True, \n","                          return_tensors=\"np\", \n","                          truncation=True, \n","                          padding='max_length')\n","        input_ids.append(token['input_ids'][0])\n","        attention_mask.append(token['attention_mask'][0])\n","    if attn_mask:\n","      return np.array(input_ids, dtype=\"int32\"), np.array(attention_mask, dtype=\"int32\")\n","    else:\n","      return np.array(input_ids, dtype=\"int32\")\n","\n","\n","def get_data(df, rubric_col, attn_mask=True): # changed\n","    inputs = bert_encode(df['full_text'], bert_tokenizer, attn_mask)  \n","    targets = np.array(df[rubric_col], dtype=\"float32\") # changed\n","    return inputs, targets"],"id":"HDyQlm2m_Tkz"},{"cell_type":"markdown","metadata":{"id":"PzmIfem-wbC8"},"source":["# Loss and Metrics Functions"],"id":"PzmIfem-wbC8"},{"cell_type":"code","execution_count":null,"metadata":{"id":"frZQl1I6RBaA"},"outputs":[],"source":["# # Using Huber loss which is less sensitive to outliers/edge cases\n","def huber_loss(y_true, y_pred, clip_delta=1.0):\n","  error = y_true - y_pred\n","  cond  = tf.keras.backend.abs(error) < clip_delta\n","\n","  squared_loss = 0.5 * tf.keras.backend.square(error)\n","  linear_loss  = clip_delta * (tf.keras.backend.abs(error) - 0.5 * clip_delta)\n","\n","  return tf.where(cond, squared_loss, linear_loss)\n","\n"],"id":"frZQl1I6RBaA"},{"cell_type":"code","execution_count":null,"metadata":{"id":"c83a5209"},"outputs":[],"source":["# Custom metric function MCRMSE : column wise root mean squared eoor\n","def MCRMSE(y_true, y_pred):\n","    colwise_mse = tf.reduce_mean(tf.square(y_true - y_pred), axis=0)\n","    return tf.reduce_mean(tf.sqrt(colwise_mse), axis=-1, keepdims=True)"],"id":"c83a5209"},{"cell_type":"markdown","metadata":{"id":"clB1IpglzX8X"},"source":["# Callbacks and LR "],"id":"clB1IpglzX8X"},{"cell_type":"code","execution_count":null,"metadata":{"id":"wU3I7VmVzM8V"},"outputs":[],"source":["#early stopping\n","earlystopper = tf.keras.callbacks.EarlyStopping(\n","      monitor='val_loss', patience = PATIENCE,\n","      restore_best_weights=True)"],"id":"wU3I7VmVzM8V"},{"cell_type":"code","execution_count":null,"metadata":{"id":"TCJcoA1izuEC"},"outputs":[],"source":["#learning rate schedule\n","def lr_scheduler(epoch, lr):\n","    \n","    if epoch < 7:\n","        return lr\n","    else:\n","        return lr * tf.math.exp(-0.1)\n","\n","lr_callback = tf.keras.callbacks.LearningRateScheduler(lr_scheduler)"],"id":"TCJcoA1izuEC"},{"cell_type":"markdown","metadata":{"id":"oUfQV7lPIgYj"},"source":["# Model Configurations"],"id":"oUfQV7lPIgYj"},{"cell_type":"code","execution_count":null,"metadata":{"id":"eRXZ8Q5lTUmJ"},"outputs":[],"source":["base_bert_config = dict(\n","    # RUBRIC_COLS = ['cohesion', 'syntax', 'vocabulary', \n","    #                'phraseology', 'grammar', 'conventions'], # changed\n","    batch_size = BATCH_SIZE,\n","    model_name = 'base_bert',\n","    epochs = EPOCHS,\n","    init_learning_rate = LEARNING_RATE,\n","    lr_decay_rate = LEARNING_RATE_DECAY,\n","    optimizer = 'adam',\n","    loss_fn = huber_loss,\n","    metrics = 'accuracy', # changed\n","    earlystopping_patience = PATIENCE\n",")"],"id":"eRXZ8Q5lTUmJ"},{"cell_type":"code","execution_count":null,"metadata":{"id":"WmkSju3sXKzh"},"outputs":[],"source":["cfg = transformers.AutoConfig.from_pretrained(\"bert-base-cased\", output_hidden_states=True) # Changed from deberta_base_fresh\n","cfg.hidden_dropout_prob = 0.3 # changed\n","cfg.attention_probs_dropout_prob = 0.3 # changed\n","# cfg.save_pretrained('./tokenizer/')"],"id":"WmkSju3sXKzh"},{"cell_type":"markdown","metadata":{"id":"aVxh7fuETpA_"},"source":["## bert Experiments"],"id":"aVxh7fuETpA_"},{"cell_type":"markdown","metadata":{"id":"yMUr92xZT_qU"},"source":["#### bert with pooled output"],"id":"yMUr92xZT_qU"},{"cell_type":"code","execution_count":null,"metadata":{"id":"qYPKHPCTTsV9"},"outputs":[],"source":["def create_bert_model(bert_model,\n","                      dropout = 0.3):\n","\n","    # Read in bert model's outputs\n","    input_ids = tf.keras.layers.Input(shape=(SEQUENCE_LENGTH,), dtype=tf.int64, name='input_ids_layer')\n","    attention_masks = tf.keras.layers.Input(shape=(SEQUENCE_LENGTH,), dtype=tf.int64, name='attention_mask_layer')\n","\n","    bert_output = bert_model.bert(\n","        input_ids, attention_mask=attention_masks\n","    )\n","    hidden_states = bert_output.last_hidden_state\n","\n","    x = tf.keras.layers.GlobalAveragePooling1D()(hidden_states)\n","    x = tf.keras.layers.LayerNormalization()(x)\n","    x = tf.keras.layers.Dropout(dropout)(x) \n","\n","    # # Prediction layer - predict cohesion via nomial classification\n","    output = tf.keras.layers.Dense(9, activation='softmax', name='classification_layer')(x) # changed\n","\n","    # # Make and compile model\n","    model = tf.keras.models.Model(inputs=(input_ids, attention_masks), outputs=[output]) \n","    model.compile(optimizer=tf.keras.optimizers.Adam(1e-5),  # changed\n","                    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False), # changed\n","                    metrics='accuracy') # changed\n","       \n","    return model"],"id":"qYPKHPCTTsV9"},{"cell_type":"markdown","metadata":{"id":"2PpYNQzeIrcv"},"source":["# Building Models"],"id":"2PpYNQzeIrcv"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6829,"status":"ok","timestamp":1669839480093,"user":{"displayName":"Kurt Eulau","userId":"04832524453730868662"},"user_tz":480},"id":"_zIGGLyJV1_8","outputId":"9f7bcbc8-e197-4440-9b5b-0719263d3c97"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"execute_result","data":{"text/plain":["23078"]},"metadata":{},"execution_count":21}],"source":["tf.keras.backend.clear_session()\n","\n","bert_model = transformers.TFAutoModel.from_pretrained(\"bert-base-cased\", config=cfg)\n","bert_pooled_model = create_bert_model(bert_model,\n","                                      dropout = 0.3)\n","\n","tf.keras.backend.clear_session()\n","\n","gc.collect()"],"id":"_zIGGLyJV1_8"},{"cell_type":"markdown","metadata":{"id":"J3MWhdMP2Hzg"},"source":["# Training Models"],"id":"J3MWhdMP2Hzg"},{"cell_type":"code","execution_count":null,"metadata":{"id":"VgEFYaMN2PVs"},"outputs":[],"source":["def train_model(model,\n","                train_df,\n","                val_df,\n","                config: dict,\n","                callbacks: list,\n","                verbose: int=0):\n","  \n","    # Initalize model\n","    tf.keras.backend.clear_session()\n","    callback = tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience = PATIENCE , restore_best_weights=True) # changed\n","\n","    model_history = model.fit(\n","      x=train_df[0],\n","      y=train_df[1],\n","      validation_data = val_df,\n","      batch_size=BATCH_SIZE,\n","      epochs=EPOCHS, # changed from EPOCHS\n","      shuffle = True, \n","      callbacks = [callback]\n","      )\n","\n","    return model_history"],"id":"VgEFYaMN2PVs"},{"cell_type":"code","source":["%%time\n","\n","pd.options.mode.chained_assignment = None\n","\n","accuracies = list()\n","RMSEs = list()\n","\n","for rubric_col in RUBRIC_COLS:\n","    print('\\n\\n////////////////////////////////////////////////////////////////////////////////////')\n","    print(f'\\nNow training on {rubric_col}...\\n')\n","    train_data, val_data, test_data = select_data(train_data_from_file,\n","                                                  validation_data_from_file,\n","                                                  test_data_from_file,\n","                                                  rubric_col)\n","    train_dataset = get_data(train_data, rubric_col)\n","    val_dataset = get_data(val_data, rubric_col)\n","    test_dataset = get_data(test_data, rubric_col)\n","\n","\n","    callbacks = [earlystopper]\n","\n","    tf.keras.backend.clear_session()\n","\n","    db_last_hidden_model = train_model(model=bert_pooled_model,\n","                            train_df = train_dataset, \n","                            val_df = val_dataset, \n","                            config=base_bert_config, \n","                            callbacks=callbacks, \n","                            verbose=1)\n","\n","    tf.keras.backend.clear_session()\n","    results = bert_pooled_model.evaluate(test_dataset[0],\n","                                         test_dataset[1])\n","    print(f'Test set accuracy for {rubric_col} is {round(results[1], 4)}.')\n","    accuracies.append(round(results[1], 4)) # Evaluate returns list of [loss, metric]\n","\n","    preds_proba = bert_pooled_model.predict(test_dataset[0])\n","    preds_0_9 = tf.argmax(preds_proba, axis=-1)\n","    ints_to_scores_vectorized = np.vectorize(ints_to_scores)\n","    preds_1_5 = ints_to_scores_vectorized(np.array(preds_0_9).astype(int))\n","    val_labels = ints_to_scores_vectorized(test_dataset[1].astype(int))\n","    RMSEs.append(sklearn.metrics.mean_squared_error(val_labels, preds_1_5, squared=False))\n","    \n","\n","mcrmse_final = np.array(RMSEs).mean()\n","print('\\n\\n====================================================================================')\n","print('Accuracies:', accuracies)\n","print('MCRMSE across all rubric columns:', round(mcrmse_final, 4))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O4MeIUdYpFi0","executionInfo":{"status":"ok","timestamp":1669841396506,"user_tz":480,"elapsed":1916415,"user":{"displayName":"Kurt Eulau","userId":"04832524453730868662"}},"outputId":"2e8be5d6-9095-4914-d754-e75ef5c0c8c8"},"id":"O4MeIUdYpFi0","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","////////////////////////////////////////////////////////////////////////////////////\n","\n","Now training on cohesion...\n","\n","Epoch 1/4\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"]},{"output_type":"stream","name":"stdout","text":["2347/2347 [==============================] - 89s 34ms/step - loss: 1.9908 - accuracy: 0.2833 - val_loss: 1.6054 - val_accuracy: 0.3223\n","Epoch 2/4\n","2347/2347 [==============================] - 75s 32ms/step - loss: 1.8685 - accuracy: 0.2944 - val_loss: 1.6621 - val_accuracy: 0.3069\n","Epoch 3/4\n","2347/2347 [==============================] - 75s 32ms/step - loss: 1.6707 - accuracy: 0.3272 - val_loss: 1.6493 - val_accuracy: 0.3056\n","Epoch 4/4\n","2347/2347 [==============================] - 75s 32ms/step - loss: 1.5648 - accuracy: 0.3711 - val_loss: 1.5870 - val_accuracy: 0.3159\n","25/25 [==============================] - 7s 147ms/step - loss: 1.5953 - accuracy: 0.3159\n","Test set accuracy for cohesion is 0.3159.\n","25/25 [==============================] - 7s 145ms/step\n","\n","\n","////////////////////////////////////////////////////////////////////////////////////\n","\n","Now training on syntax...\n","\n","Epoch 1/4\n","2347/2347 [==============================] - 78s 32ms/step - loss: 1.5927 - accuracy: 0.3409 - val_loss: 1.7583 - val_accuracy: 0.2698\n","Epoch 2/4\n","2347/2347 [==============================] - 75s 32ms/step - loss: 1.4454 - accuracy: 0.3856 - val_loss: 1.7380 - val_accuracy: 0.2903\n","Epoch 3/4\n","2347/2347 [==============================] - 77s 33ms/step - loss: 1.3519 - accuracy: 0.4256 - val_loss: 1.8721 - val_accuracy: 0.2698\n","Epoch 4/4\n","2347/2347 [==============================] - 76s 32ms/step - loss: 1.2310 - accuracy: 0.4772 - val_loss: 2.0457 - val_accuracy: 0.2749\n","25/25 [==============================] - 4s 147ms/step - loss: 2.0590 - accuracy: 0.3043\n","Test set accuracy for syntax is 0.3043.\n","25/25 [==============================] - 4s 145ms/step\n","\n","\n","////////////////////////////////////////////////////////////////////////////////////\n","\n","Now training on vocabulary...\n","\n","Epoch 1/4\n","2347/2347 [==============================] - 78s 32ms/step - loss: 1.3604 - accuracy: 0.4129 - val_loss: 1.4175 - val_accuracy: 0.4130\n","Epoch 2/4\n","2347/2347 [==============================] - 75s 32ms/step - loss: 1.2372 - accuracy: 0.4614 - val_loss: 1.3778 - val_accuracy: 0.4514\n","Epoch 3/4\n","2347/2347 [==============================] - 75s 32ms/step - loss: 1.1541 - accuracy: 0.4972 - val_loss: 1.6280 - val_accuracy: 0.4118\n","Epoch 4/4\n","2347/2347 [==============================] - 75s 32ms/step - loss: 1.0576 - accuracy: 0.5394 - val_loss: 1.6460 - val_accuracy: 0.4105\n","25/25 [==============================] - 5s 147ms/step - loss: 1.7915 - accuracy: 0.3887\n","Test set accuracy for vocabulary is 0.3887.\n","25/25 [==============================] - 4s 145ms/step\n","\n","\n","////////////////////////////////////////////////////////////////////////////////////\n","\n","Now training on phraseology...\n","\n","Epoch 1/4\n","2347/2347 [==============================] - 78s 32ms/step - loss: 1.3744 - accuracy: 0.3967 - val_loss: 1.5570 - val_accuracy: 0.3453\n","Epoch 2/4\n","2347/2347 [==============================] - 75s 32ms/step - loss: 1.2835 - accuracy: 0.4265 - val_loss: 1.5690 - val_accuracy: 0.3517\n","Epoch 3/4\n","2347/2347 [==============================] - 75s 32ms/step - loss: 1.1825 - accuracy: 0.4742 - val_loss: 1.8113 - val_accuracy: 0.3223\n","Epoch 4/4\n","2347/2347 [==============================] - 75s 32ms/step - loss: 1.0522 - accuracy: 0.5275 - val_loss: 2.2452 - val_accuracy: 0.2877\n","25/25 [==============================] - 4s 146ms/step - loss: 2.2340 - accuracy: 0.2775\n","Test set accuracy for phraseology is 0.2775.\n","25/25 [==============================] - 4s 144ms/step\n","\n","\n","////////////////////////////////////////////////////////////////////////////////////\n","\n","Now training on grammar...\n","\n","Epoch 1/4\n","2347/2347 [==============================] - 77s 32ms/step - loss: 1.4102 - accuracy: 0.3813 - val_loss: 1.6013 - val_accuracy: 0.3223\n","Epoch 2/4\n","2347/2347 [==============================] - 74s 32ms/step - loss: 1.2942 - accuracy: 0.4124 - val_loss: 1.5897 - val_accuracy: 0.3171\n","Epoch 3/4\n","2347/2347 [==============================] - 75s 32ms/step - loss: 1.1796 - accuracy: 0.4781 - val_loss: 1.9588 - val_accuracy: 0.2839\n","Epoch 4/4\n","2347/2347 [==============================] - 75s 32ms/step - loss: 1.0621 - accuracy: 0.5224 - val_loss: 2.1402 - val_accuracy: 0.2749\n","25/25 [==============================] - 5s 147ms/step - loss: 1.9888 - accuracy: 0.3402\n","Test set accuracy for grammar is 0.3402.\n","25/25 [==============================] - 4s 145ms/step\n","\n","\n","////////////////////////////////////////////////////////////////////////////////////\n","\n","Now training on conventions...\n","\n","Epoch 1/4\n","2347/2347 [==============================] - 78s 32ms/step - loss: 1.3309 - accuracy: 0.3971 - val_loss: 1.6984 - val_accuracy: 0.3261\n","Epoch 2/4\n","2347/2347 [==============================] - 75s 32ms/step - loss: 1.2093 - accuracy: 0.4593 - val_loss: 1.6040 - val_accuracy: 0.3338\n","Epoch 3/4\n","2347/2347 [==============================] - 75s 32ms/step - loss: 1.0933 - accuracy: 0.5109 - val_loss: 1.7539 - val_accuracy: 0.3402\n","Epoch 4/4\n","2347/2347 [==============================] - 75s 32ms/step - loss: 0.9595 - accuracy: 0.5850 - val_loss: 2.0318 - val_accuracy: 0.3223\n","25/25 [==============================] - 5s 146ms/step - loss: 2.0988 - accuracy: 0.3274\n","Test set accuracy for conventions is 0.3274.\n","25/25 [==============================] - 4s 146ms/step\n","\n","\n","====================================================================================\n","Accuracies: [0.3159, 0.3043, 0.3887, 0.2775, 0.3402, 0.3274]\n","MCRMSE across all rubric columns: 0.6289\n","CPU times: user 34min 37s, sys: 1min 19s, total: 35min 57s\n","Wall time: 31min 56s\n"]}]},{"cell_type":"code","source":["pd.DataFrame({'Rubric Column': RUBRIC_COLS, 'Accuracy': accuracies})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":237},"id":"U0MYJ8qeUGR4","executionInfo":{"status":"ok","timestamp":1669841592748,"user_tz":480,"elapsed":154,"user":{"displayName":"Kurt Eulau","userId":"04832524453730868662"}},"outputId":"1391966f-ef9d-4851-8235-3e41e188f5b2"},"id":"U0MYJ8qeUGR4","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["  Rubric Column  Accuracy\n","0      cohesion    0.3159\n","1        syntax    0.3043\n","2    vocabulary    0.3887\n","3   phraseology    0.2775\n","4       grammar    0.3402\n","5   conventions    0.3274"],"text/html":["\n","  <div id=\"df-b2c0eeaa-22d1-40ab-a97b-0b92f142e8f7\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Rubric Column</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>cohesion</td>\n","      <td>0.3159</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>syntax</td>\n","      <td>0.3043</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>vocabulary</td>\n","      <td>0.3887</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>phraseology</td>\n","      <td>0.2775</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>grammar</td>\n","      <td>0.3402</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>conventions</td>\n","      <td>0.3274</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b2c0eeaa-22d1-40ab-a97b-0b92f142e8f7')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-b2c0eeaa-22d1-40ab-a97b-0b92f142e8f7 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-b2c0eeaa-22d1-40ab-a97b-0b92f142e8f7');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["pd.DataFrame({'Rubric Column': RUBRIC_COLS, 'RMSE': RMSEs})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":237},"id":"U90Yy1FoOE2i","executionInfo":{"status":"ok","timestamp":1669841397547,"user_tz":480,"elapsed":4,"user":{"displayName":"Kurt Eulau","userId":"04832524453730868662"}},"outputId":"28946047-97d0-4915-9333-847b9bc56ed2"},"id":"U90Yy1FoOE2i","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["  Rubric Column      RMSE\n","0      cohesion  0.597844\n","1        syntax  0.630126\n","2    vocabulary  0.562580\n","3   phraseology  0.701660\n","4       grammar  0.647887\n","5   conventions  0.633415"],"text/html":["\n","  <div id=\"df-4b942296-9470-4df8-832a-5a751348b07c\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Rubric Column</th>\n","      <th>RMSE</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>cohesion</td>\n","      <td>0.597844</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>syntax</td>\n","      <td>0.630126</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>vocabulary</td>\n","      <td>0.562580</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>phraseology</td>\n","      <td>0.701660</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>grammar</td>\n","      <td>0.647887</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>conventions</td>\n","      <td>0.633415</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4b942296-9470-4df8-832a-5a751348b07c')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-4b942296-9470-4df8-832a-5a751348b07c button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-4b942296-9470-4df8-832a-5a751348b07c');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":32}]},{"cell_type":"markdown","metadata":{"id":"03db3ebf"},"source":["# Prediction + Submission"],"id":"03db3ebf"},{"cell_type":"code","source":["# preds_proba = bert_pooled_model.predict(val_dataset[0])\n","# preds_proba"],"metadata":{"id":"viHVNqpCd7Di"},"id":"viHVNqpCd7Di","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# preds_0_9 = tf.argmax(preds_proba, axis=-1)\n","# preds_0_9[:20]"],"metadata":{"id":"W7zd5Fteebyu"},"id":"W7zd5Fteebyu","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ints_to_scores_vectorized = np.vectorize(ints_to_scores)"],"metadata":{"id":"Wv83HAqigL3d"},"id":"Wv83HAqigL3d","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# preds_1_5 = ints_to_scores_vectorized(np.array(preds_0_9).astype(int))\n","# preds_1_5[:20]"],"metadata":{"id":"LIu709WwgOpp"},"id":"LIu709WwgOpp","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# val_labels = ints_to_scores_vectorized(val_dataset[1].astype(int))\n","# val_labels[:20]"],"metadata":{"id":"8DHKy7vahxvM"},"id":"8DHKy7vahxvM","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# sklearn.metrics.mean_squared_error(val_labels, preds_1_5, squared=False)"],"metadata":{"id":"kR1wvKbWgxsz"},"id":"kR1wvKbWgxsz","execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[{"file_id":"1xHHoo3ndxfRT5n6SqLpl43Lovoo0H4ID","timestamp":1668995260169},{"file_id":"1PYoyeccegOeOXoMlLQGOsC34jST0wxmH","timestamp":1668984091622},{"file_id":"1VncoYfoa7Suog-5zq_VJlmwAsnJHY3gP","timestamp":1668960919745},{"file_id":"1c85_cBGeHnEX9OkmLcZXcljDPEGyDvg3","timestamp":1668893041333},{"file_id":"1IJuRuDVqZTCTu_lrzdd2Ga4X7xFlY3xX","timestamp":1664644852234}]},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"papermill":{"default_parameters":{},"duration":987.955368,"end_time":"2022-09-21T23:17:00.351231","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2022-09-21T23:00:32.395863","version":"2.3.4"}},"nbformat":4,"nbformat_minor":5}